# CVPR 2021 - Robotics paper list-up

# State estimation and Localization

Fusing the Old with the New: Learning Relative Camera Pose with Geometry-Guided Uncertainty

Glancing at the Patch: Anomaly Localization With Global and Local Feature Comparison

Globally Optimal Relative Pose Estimation With Gravity Prior

Neural Reprojection Error: Merging Feature Learning and Camera Pose Estimation

Rotation-Only Bundle Adjustment

Keypoint-Graph-Driven Learning Framework for Object Pose Estimation

Self-Supervised Motion Learning From Static Images

Deep Homography for Efficient Stereo Image Compression

Privacy Preserving Localization and Mapping From Uncalibrated Cameras // Marc Pollefeys

Learning Camera Localization via Dense Scene Matching

PlückerNet: Learn To Register 3D Line Reconstructions

Feature-Level Collaboration: Joint Unsupervised Learning of Optical Flow, Stereo Depth and Camera Motion

HybrIK: A Hybrid Analytical-Neural Inverse Kinematics Solution for 3D Human Pose and Shape Estimation

VIGOR: Cross-View Image Geo-Localization Beyond One-to-One Retrieval

Predator: Registration of 3D Point Clouds With Low Overlap

Rotation Coordinate Descent for Fast Globally Optimal Rotation Averaging

Uncertainty-Aware Camera Pose Estimation From Points and Lines

Spatiotemporal Registration for Event-Based Visual Odometry

VS-Net: Voting With Segmentation for Visual Localization

Coming Down to Earth: Satellite-to-Street View Synthesis for Geo-Localization

OBoW: Online Bag-of-Visual-Words Generation for Self-Supervised Learning

UnsupervisedR&R: Unsupervised Point Cloud Registration via Differentiable Rendering

Mesoscopic Photogrammetry With an Unstabilized Phone Camera

Neural Camera Simulators

Robust Neural Routing Through Space Partitions for Camera Relocalization in Dynamic Indoor Environments

Robust Point Cloud Registration Framework Based on Deep Graph Matching

Deep Two-View Structure-From-Motion Revisited

Learning Neural Representation of Camera Pose with Matrix Representation of Pose Shift via View Synthesis

Stay Positive: Non-Negative Image Synthesis for Augmented Reality // Serge Belongie

Tangent Space Backpropagation for 3D Transformation Groups

Hybrid Rotation Averaging: A Fast and Robust Rotation Averaging Approach

Square Root Bundle Adjustment for Large-Scale Reconstruction

End-to-End Rotation Averaging With Multi-Source Propagation

Extreme Rotation Estimation Using Dense Correlation Volumes

Efficient Initial Pose-Graph Generation for Global SfM

PWCLO-Net: Deep LiDAR Odometry in 3D Point Clouds Using Hierarchical Embedding Mask Optimization

Deep Lucas-Kanade Homography for Multimodal Image Alignment

# Mapping, Reconstruction, Rendering

### Mapping and Reconstruction (Scene)

Learning Delaunay Surface Elements for Mesh Reconstruction

Learning To Recover 3D Scene Shape From a Single Image

Neural Deformation Graphs for Globally-Consistent Non-Rigid Reconstruction

Learning Monocular 3D Reconstruction of Articulated Categories From Motion

Deep Implicit Moving Least-Squares Functions for 3D Reconstruction

NeuralFusion: Online Depth Fusion in Latent Space

HDMapGen: A Hierarchical Graph Generative Model of High Definition Maps

MonoRec: Semi-Supervised Dense Reconstruction in Dynamic Environments From a Single Moving Camera

HDR Environment Map Estimation for Real-Time Augmented Reality

Indoor Panorama Planar 3D Reconstruction via Divide and Conquer

MP3: A Unified Model To Map, Perceive, Predict and Plan // Raquel 

NeuralRecon: Real-Time Coherent 3D Reconstruction From Monocular Video

### Reconstruction (Human, Object)

End-to-End Human Pose and Mesh Reconstruction with Transformers

Deep Implicit Templates for 3D Shape Representation

Single-View 3D Object Reconstruction From Shape Priors in Memory

Deep Optimized Priors for 3D Shape Modeling and Reconstruction

Self-Supervised 3D Mesh Reconstruction From Single Images

Neural Body: Implicit Neural Representations With Structured Latent Codes for Novel View Synthesis of Dynamic Humans

DeepSurfels: Learning Online Appearance Fusion

### Neural Rendering

Pulsar: Efficient Sphere-Based Neural Rendering

DI-Fusion: Online Implicit 3D Reconstruction With Deep Priors

pixelNeRF: Neural Radiance Fields From One or Few Images

Neural Surface Maps

NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections

NeRV: Neural Reflectance and Visibility Fields for Relighting and View Synthesis

Stereo Radiance Fields (SRF): Learning View Synthesis for Sparse Views of Novel Scenes

Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction // Matthias Nießner

Self-Supervised Visibility Learning for Novel View Synthesis

D-NeRF: Neural Radiance Fields for Dynamic Scenes

GIRAFFE: Representing Scenes As Compositional Generative Neural Feature Fields

Stable View Synthesis

DeRF: Decomposed Radiance Fields

# Depth est.

Robust Consistent Video Depth Estimation

Depth Completion With Twin Surface Extrapolation at Occlusion Boundaries

S2R-DepthNet: Learning a Generalizable Depth-Specific Structural Representation

AdaBins: Depth Estimation Using Adaptive Bins

EDNet: Efficient Disparity Estimation With Cost Volume Combination and Attention-Based Spatial Residual

PLADE-Net: Towards Pixel-Level Accuracy for Self-Supervised Single-View Depth Estimation With Neural Positional Encoding and Distilled Matting Loss

Beyond Image to Depth: Improving Depth Prediction Using Echoes

Sparse Auxiliary Networks for Unified Monocular Depth Prediction and Completion // TRI

Radar-Camera Pixel Depth Association for Depth Completion

Monocular Depth Estimation via Listwise Ranking Using the Plackett-Luce ModelExtreme Rotation Estimation Using Dense Correlation Volumes

Camera Pose Matters: Improving Depth Prediction by Mitigating Pose Distribution Bias

S3: Learnable Sparse Signal Superdensity for Guided Depth Estimation

# Navigation

Structured Scene Memory for Vision-Language Navigation

Pushing It Out of the Way: Interactive Visual Navigation

Differentiable SLAM-Net: Learning Particle SLAM for Visual Navigation

# Matching

### Local Feature

Skeleton Merger: An Unsupervised Aligned Keypoint Detector

Limitations of Post-Hoc Feature Alignment for Robustness

Convolutional Hough Matching Networks

Back to the Feature: Learning Robust Camera Localization From Pixels To Pose

Patch2Pix: Epipolar-Guided Pixel-Level Correspondences

LoFTR: Detector-Free Local Feature Matching With Transformers

SOLD2: Self-Supervised Occlusion-Aware Line Description and Detection

Learning To Identify Correct 2D-2D Line Correspondences on Sphere

Leveraging Line-Point Consistence To Preserve Structures for Wide Parallax Image Stitching

KeypointDeformer: Unsupervised 3D Keypoint Discovery for Shape Control

Privacy-Preserving Image Features via Adversarial Affine Subspace Embeddings // Marc Pollefeys 

### Others

On Semantic Similarity in Video Retrieval

# Recognition, Retrieval

Neural Feature Search for RGB-Infrared Person Re-Identification

Image Change Captioning by Learning From an Auxiliary Task

T2VLAD: Global-Local Sequence Alignment for Text-Video Retrieval

Learning Cross-Modal Retrieval With Noisy Labels

Probabilistic Embeddings for Cross-Modal Retrieval

SOE-Net: A Self-Attention and Orientation Encoding Network for Point Cloud Based Place Recognition

Nearest Neighbor Matching for Deep Clustering

Patch-NetVLAD: Multi-Scale Fusion of Locally-Global Descriptors for Place Recognition

Efficient Object Embedding for Spliced Image Retrieval

# Perception

### Segmentation

Fully Convolutional Networks for Panoptic Segmentation

Exemplar-Based Open-Set Panoptic Segmentation Network

Incremental Few-Shot Instance Segmentation

Semi-Supervised Semantic Segmentation With Directional Context-Aware Consistency

SwiftNet: Real-Time Video Object Segmentation

Efficient Regional Memory Network for Video Object Segmentation

Learning To Segment Rigid Motions From Two Frames

Zero-Shot Instance Segmentation

Semi-Supervised Semantic Segmentation With Cross Pseudo Supervision

ABMDRNet: Adaptive-Weighted Bi-Directional Modality Difference Reduction Network for RGB-T Semantic Segmentation

BBAM: Bounding Box Attribution Map for Weakly Supervised Semantic and Instance Segmentation

MeanShift++: Extremely Fast Mode-Seeking With Applications to Segmentation and Object Tracking

Part-Aware Panoptic Segmentation

MaX-DeepLab: End-to-End Panoptic Segmentation With Mask Transformers

Rethinking Semantic Segmentation From a Sequence-to-Sequence Perspective With Transformers

End-to-End Video Instance Segmentation With Transformers

Seesaw Loss for Long-Tailed Instance Segmentation

Exploit Visual Dependency Relations for Semantic Segmentation

Locate Then Segment: A Strong Pipeline for Referring Image Segmentation

Cylindrical and Asymmetrical 3D Convolution Networks for LiDAR Segmentation

Cross-View Regularization for Domain Adaptive Panoptic Segmentation

Three Ways To Improve Semantic Segmentation With Self-Supervised Depth Estimation // Luc Van Gool

Look Closer To Segment Better: Boundary Patch Refinement for Instance Segmentation

Self-Supervised Augmentation Consistency for Adapting Semantic Segmentation

Progressive Semantic Segmentation

LPSNet: A Lightweight Solution for Fast Panoptic Segmentation

### Object Detection

AQD: Towards Accurate Quantized Object Detection

RankDetNet: Delving Into Ranking Constraints for Object Detection

GAIA: A Transfer Learning System of Object Detection That Fits Your Needs

OTA: Optimal Transport Assignment for Object Detection

Depth-Conditioned Dynamic Message Propagation for Monocular 3D Object Detection

Depth From Camera Motion and Object Detection

UP-DETR: Unsupervised Pre-Training for Object Detection With Transformers

Equalization Loss v2: A New Gradient Balance Approach for Long-Tailed Object Detection

Distilling Object Detectors via Decoupled Features

Positive-Unlabeled Data Purification in the Wild for Object Detection

ReDet: A Rotation-Equivariant Detector for Aerial Object Detection

PANDA: Adapting Pretrained Features for Anomaly Detection and Segmentation

Transformation Invariant Few-Shot Object Detection

Humble Teachers Teach Better Students for Semi-Supervised Object Detection

Objects Are Different: Flexible Monocular 3D Object Detection

MobileDets: Searching for Object Detection Architectures for Mobile Accelerators

Line Segment Detection Using Transformers Without Edges

Generalized Few-Shot Object Detection Without Forgetting

Delving Into Localization Errors for Monocular 3D Object Detection

Towards Open World Object Detection

RSN: Range Sparse Net for Efficient, Accurate LiDAR 3D Object Detection

Interactive Self-Training With Mean Teachers for Semi-Supervised Object Detection

Unsupervised Object Detection With LIDAR Clues

M3DSSD: Monocular 3D Single Stage Object Detector

RangeIoUDet: Range Image Based Real-Time 3D Object Detector Optimized by Intersection Over Union

3D Object Detection With Pointformer

Neural Auto-Exposure for High-Dynamic Range Object Detection

VarifocalNet: An IoU-Aware Dense Object Detector

Categorical Depth Distribution Network for Monocular 3D Object Detection

Points As Queries: Weakly Semi-Supervised Object Detection by Points

Informative and Consistent Correspondence Mining for Cross-Domain Weakly Supervised Object Detection

MonoRUn: Monocular 3D Object Detection by Reconstruction and Uncertainty Propagation

Generalized Focal Loss V2: Learning Reliable Localization Quality Estimation for Dense Object Detection

PointAugmenting: Cross-Modal Augmentation for 3D Object Detection

Scaled-YOLOv4: Scaling Cross Stage Partial Network

3DIoUMatch: Leveraging IoU Prediction for Semi-Supervised 3D Object Detection

### Scene Flow

UPFlow: Upsampling Pyramid for Unsupervised Optical Flow Learning

Self-Supervised Multi-Frame Monocular Scene Flow

FlowStep3D: Model Unrolling for Self-Supervised Scene Flow Estimation

RAFT-3D: Scene Flow Using Rigid-Motion Embeddings

AutoFlow: Learning a Better Training Set for Optical Flow

Learning Optical Flow From Still Images

Learning Optical Flow From a Few Matches

### Scene Understanding

HoHoNet: 360 Indoor Holistic Understanding With Latent Horizontal Features

Neural Scene Graphs for Dynamic Scenes

Scan2Cap: Context-Aware Dense Captioning in RGB-D Scans

LayoutTransformer: Scene Layout Generation With Conceptual and Spatial Diversity

3D-to-2D Distillation for Indoor Scene Parsing

Visual Room Rearrangement

Fully Understanding Generic Objects: Modeling, Segmentation, and Reconstruction

Towards Part-Based Understanding of RGB-D Scans

Scene Essence

Holistic 3D Scene Understanding From a Single Image With Implicit Representation

Plan2Scene: Converting Floorplans to 3D Scenes

LED2-Net: Monocular 360° Layout Estimation via Differentiable Depth Rendering

Learning View Selection for 3D Scenes

SSLayout360: Semi-Supervised Indoor Layout Estimation From 360° Panorama

### Others

Quasi-Dense Similarity Learning for Multiple Object Tracking

Recorrupted-to-Recorrupted: Unsupervised Deep Learning for Image Denoising

Deep Denoising of Flash and No-Flash Pairs for Photography in Low-Light Environments

From Shadow Generation To Shadow Removal

MultiBodySync: Multi-Body Segmentation and Motion Estimation via 3D Scan Synchronization

Probabilistic Model Distillation for Semantic Correspondence

CanonPose: Self-Supervised Monocular 3D Human Pose Estimation in the Wild

Masksembles for Uncertainty Estimation

Self-Supervised Geometric Perception // Hank, Luca, Vladlen Koltun

# 3D DL

Point Cloud Upsampling via Disentangled Refinement

DyCo3D: Robust Instance Segmentation of 3D Point Clouds Through Dynamic Convolution

Semantic Segmentation for Real Point Cloud Scenes via Bilateral Augmentation and Adaptive Fusion

Diffusion Probabilistic Models for 3D Point Cloud Generation

Cross-Modal Center Loss for 3D Cross-Modal Retrieval

PAConv: Position Adaptive Convolution With Dynamic Kernel Assembling on Point Clouds

StickyPillars: Robust and Efficient Feature Matching on Point Clouds Using Graph Neural Networks

Point2Skeleton: Learning Skeletal Representations from Point Clouds

LiDAR-Aug: A General Rendering-Based Augmentation Framework for 3D Object Detection

4D Panoptic LiDAR Segmentation

VoxelContext-Net: An Octree Based Framework for Point Cloud Compression

CorrNet3D: Unsupervised End-to-End Learning of Dense Correspondence for 3D Point Clouds

PointGuard: Provably Robust 3D Point Cloud Classification

TearingNet: Point Cloud Autoencoder To Learn Topology-Friendly Representations

LiDAR R-CNN: An Efficient and Universal 3D Object Detector

Self-Supervised Learning on 3D Point Clouds by Learning Discrete Generative Models

Variational Relational Point Completion Network

Few-Shot 3D Point Cloud Semantic Segmentation

Point Cloud Instance Segmentation Using Probabilistic Embeddings

Learning Progressive Point Embeddings for 3D Point Cloud Generation

PU-GCN: Point Cloud Upsampling Using Graph Convolutional Networks

Joint Learning of 3D Shape Retrieval and Deformation

SpinNet: Learning a General Surface Descriptor for 3D Point Cloud Registration

CoCoNets: Continuous Contrastive 3D Scene Representations

PointNetLK Revisited

LiDAR-Based Panoptic Segmentation via Dynamic Shifting Network

RPSRNet: End-to-End Trainable Rigid Point Set Registration Network Using Barnes-Hut 2D-Tree Representation

Picasso: A CUDA-Based Library for Deep Learning Over 3D Meshes

FESTA: Flow Estimation via Spatial-Temporal Attention for Scene Point Clouds

Point 4D Transformer Networks for Spatio-Temporal Modeling in Point Cloud Videos

SE-SSD: Self-Ensembling Single-Stage Object Detector From Point Cloud

Equivariant Point Network for 3D Point Cloud Analysis

SCF-Net: Learning Spatial Contextual Features for Large-Scale Point Cloud Segmentation

Self-Point-Flow: Self-Supervised Scene Flow Estimation From Point Clouds With Optimal Transport and Random Walk

PointDSC: Robust Point Cloud Registration Using Deep Spatial Consistency

View-Guided Point Cloud Completion

DeepI2P: Image-to-Point Cloud Registration via Deep Classification

# Dataset

SAIL-VOS 3D: A Synthetic Dataset and Baselines for Object Detection and 3D Mesh Reconstruction From Video Data

Zillow Indoor Dataset: Annotated Floor Plans With 360° Panoramas and 3D Room Layouts

Large-Scale Localization Datasets in Crowded Indoor Spaces

OpenRooms: An Open Framework for Photorealistic Indoor Scene Datasets

# Autonomous Driving

Self-Supervised Pillar Motion Learning for Autonomous Driving

AdvSim: Generating Safety-Critical Scenarios for Self-Driving Vehicles

# Neural Network and Training

### Augmentation

KeepAugment: A Simple Information-Preserving Data Augmentation Approach

SelfAugment: Automatic Augmentation Policies for Self-Supervised Learning

Augmentation Strategies for Learning With Noisy Labels

PoseAug: A Differentiable Pose Augmentation Framework for 3D Human Pose Estimation

On Feature Normalization and Data Augmentation

SuperMix: Supervising the Mixing Data Augmentation

StyleMix: Separating Content and Style for Enhanced Data Augmentation

### Architecture

Rethinking Channel Dimensions for Efficient Model Design

Fast and Accurate Model Scaling  // Ross Girshick

RepVGG: Making VGG-Style ConvNets Great Again

### Labeling

ProSelfLC: Progressive Self Label Correction for Training Robust Deep Neural Networks

Correlated Input-Dependent Label Noise in Large-Scale Image Classification

Can We Characterize Tasks Without Labels or Features?

Re-Labeling ImageNet: From Single to Multi-Labels, From Global to Localized Labels

All Labels Are Not Created Equal: Enhancing Semi-Supervision via Label Grouping and Co-Training

Joint Negative and Positive Learning for Noisy Labels

OpenMix: Reviving Known Knowledge for Discovering Novel Visual Categories in an Open World

### Bayesian

Robust Bayesian Neural Networks by Spectral Expectation Bound Regularization

Bayesian Nested Neural Networks for Uncertainty Calibration and Adaptive Compression

### Train

Contrastive Embedding for Generalized Zero-Shot Learning

Dense Contrastive Learning for Self-Supervised Visual Pre-Training

A Large-Scale Study on Unsupervised Spatiotemporal Representation Learning // Ross Girshick, Kaiming He

Revisiting Knowledge Distillation: An Inheritance and Exploration Framework

Jo-SRC: A Contrastive Approach for Combating Noisy Labels

SelfDoc: Self-Supervised Document Representation Learning

Vectorization and Rasterization: Self-Supervised Learning for Sketch and Handwriting

Model-Contrastive Federated Learning

Neighborhood Contrastive Learning for Novel Class Discovery

Metadata Normalization

PixMatch: Unsupervised Domain Adaptation via Pixelwise Consistency Training

Learning by Watching

Are Labels Always Necessary for Classifier Accuracy Evaluation?

### Knowledge Transfer

How Well Do Self-Supervised Models Transfer?

UniT: Unified Knowledge Transfer for Any-Shot Object Detection and Segmentation

### Interpretation

Where and What? Examining Interpretable Disentangled Representations

Transformer Interpretability Beyond Attention Visualization

### Loss

On Focal Loss for Class-Posterior Probability Estimation: A Theoretical Perspective

An Alternative Probabilistic Interpretation of the Huber Loss

# Generative, Style

Rethinking and Improving the Robustness of Image Style Transfer

Style-Aware Normalized Loss for Improving Arbitrary Style Transfer

Encoding in Style: A StyleGAN Encoder for Image-to-Image Translation

Navigating the GAN Parameter Space for Semantic Image Editing

Learning To Warp for Style Transfer

Image-to-Image Translation via Hierarchical Style Disentanglement

Rethinking Style Transfer: From Pixels to Parameterized Brushstrokes

# Others

Body Meshes as Points

Differentiable Patch Selection for Image Recognition

Consistent Instance False Positive Improves Fairness in Face Recognition

Polarimetric Normal Stereo

The Lottery Ticket Hypothesis for Object Recognition

Cross-Modal Contrastive Learning for Text-to-Image Generation

Contrastive Learning Based Hybrid Networks for Long-Tailed Image Classification

LiBRe: A Practical Bayesian Approach to Adversarial Detection

Generalized Domain Adaptation

Spatially Consistent Representation Learning

Bi-GCN: Binary Graph Convolutional Network

Binary Graph Neural Networks
